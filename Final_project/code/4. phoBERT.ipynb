{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install fairseq\n",
    "# !pip3 install fastbpe\n",
    "# !pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download và giải nén model từ package transformers\n",
    "# wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
    "# tar -xzvf PhoBERT_base_transformers.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from transformers.modeling_utils import * \n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fairseq.models.roberta import RobertaModel\n",
    "# from fairseq.data.encoders.fastbpe import fastBPE\n",
    "# from fairseq.data import Dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../dataset/final_data.1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rate                  0\n",
       "Review                0\n",
       "Label                 0\n",
       "Preprocess_Review    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data[\"Preprocess_Review\"]\n",
    "labels = data[\"Label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chia tập train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(reviews, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0, 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0, 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sử dụng PhoBERT là feature extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load model pretrained PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load model phoBert và tokenizer của model đó\n",
    "phoBert = AutoModel.from_pretrained('vinai/phobert-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenize văn bản và đưa về một kích thước cố định"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đưa từng sentence qua tokenizer của PhoBERT để convert sang dạng token index với cùng chiều dài\n",
    "# params\n",
    "MAX_SEQ_LEN = 256 # chiều dài tối đa của một câu\n",
    "# id của 1 số token đặc biệt\n",
    "cls_id = 0  # đầu câu\n",
    "eos_id = 2  # cuối câu\n",
    "pad_id = 1  # padding\n",
    "\n",
    "# Hàm xử lý dữ liệu trên từng sentence\n",
    "def tokenize_line(line):\n",
    "  tokenized = tokenizer.encode(line)\n",
    "  \n",
    "  l = len(tokenized)\n",
    "  if l > MAX_SEQ_LEN: # nếu dài hơn thì cắt bỏ\n",
    "    tokenized = tokenized[:MAX_SEQ_LEN]\n",
    "    tokenized[-1] = eos_id # thêm EOS vào cuối câu\n",
    "  else: # nếu ngắn hơn thì thêm padding vào\n",
    "    tokenized = tokenized + [pad_id, ] * (MAX_SEQ_LEN - l)\n",
    "  \n",
    "  return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encode:  [0, 70, 3014, 15947, 1565, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Token size:  256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ví dụ\n",
    "tokenized = tokenize_line('tôi khỏe')\n",
    "print('After encode: ', tokenized)\n",
    "print('Token size: ', len(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing train set ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3287e99b69b140ae99ce4bdc82424d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (263 > 256). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing test set ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb644e785bd64857bddd383f1e29f492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done after 2 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Xử lý trên toàn tập dữ liệu\n",
    "tokenized_train_x = []\n",
    "tokenized_test_x = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print('Tokenizing train set ...')\n",
    "for x in tqdm(train_x):\n",
    "  tokenized_train_x.append(tokenize_line(x))\n",
    "\n",
    "print('Tokenizing test set ... ')\n",
    "for x in tqdm(test_x):\n",
    "  tokenized_test_x.append(tokenize_line(x))\n",
    "\n",
    "print('Done after %d seconds' %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tạo attention mask để model chỉ tập trung vào phần nội dung mà không quan tâm tới phần padding\n",
    "train_attention_mask = []\n",
    "for x in tokenized_train_x:\n",
    "  train_attention_mask.append(np.where(np.array(x) == 1, 0, 1))\n",
    "\n",
    "test_attention_mask = []\n",
    "for x in tokenized_test_x:\n",
    "  test_attention_mask.append(np.where(np.array(x) == 1, 0, 1))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 256\n"
     ]
    }
   ],
   "source": [
    "print(train_attention_mask[10], len(train_attention_mask[10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Đưa dữ liệu kèm theo attention mash vào model PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhdu\\AppData\\Local\\Temp\\ipykernel_18272\\4075655186.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  attention_mask = torch.tensor(train_attention_mask[:1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert sang tensor\n",
    "tokenized = torch.tensor(tokenized_train_x[:1]).to(torch.long)\n",
    "attention_mask = torch.tensor(train_attention_mask[:1])\n",
    "\n",
    "with torch.no_grad():\n",
    "  last_hidden_states = phoBert(input_ids=tokenized, attention_mask=attention_mask)\n",
    "\n",
    "print(last_hidden_states[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nhận xét:*** Dữ liệu trả về là một tensor có size là (1,256,768) trong đó 1 là số sentence truyền vào, 256 là độ dài mỗi sentence và 768 là vector embedding cho mỗi word của sentence đó. Bởi vì ta sẽ sử dụng vector embedding của token CLS để classify nên ta sẽ lấy vector embedding của từ đầu tiên của mọi câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector embedding của train set\n",
    "tokenized = torch.tensor(tokenized_train_x[:]).to(torch.long)\n",
    "attention_mask = torch.tensor(train_attention_mask[:])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "  last_hidden_states = phoBert(input_ids=tokenized, attention_mask=attention_mask)\n",
    "\n",
    "train_features = last_hidden_states[0][:, 0, :].numpy()\n",
    "print('Finish extracting features after %d seconds' %(time.time() - start))\n",
    "\n",
    "print('Output shape: ', train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm extract feature của 1 line\n",
    "def extract_line(tokenized, mask):\n",
    "  tokenized = torch.tensor(tokenized).to(torch.long)\n",
    "  mask = torch.tensor(mask)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    last_hidden_states = phoBert(input_ids=tokenized, attention_mask=mask)\n",
    "  \n",
    "  feature = last_hidden_states[0][:, 0, :].numpy()\n",
    "\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.45886883e-01,  4.27036107e-01, -2.68668413e-01,\n",
       "        -6.65369391e-01, -9.71091688e-02, -3.94507557e-01,\n",
       "         3.59896243e-01, -3.44905198e-01, -2.16611221e-01,\n",
       "         2.18474507e-01, -1.73639789e-01, -3.02961111e-01,\n",
       "        -3.46201658e-03,  4.33996320e-01,  6.83624685e-01,\n",
       "         8.70250165e-02, -2.64169753e-01, -2.88108408e-01,\n",
       "         2.90218741e-03, -4.64014769e-01,  4.41070974e-01,\n",
       "        -1.27252877e+00,  6.80580616e-01, -2.86518931e-02,\n",
       "         1.73290893e-01,  3.42010677e-01,  1.10351369e-01,\n",
       "        -8.96850228e-03, -2.76633084e-01,  4.97711331e-01,\n",
       "        -2.02434570e-01, -2.44635433e-01,  1.85743377e-01,\n",
       "         1.86224848e-01,  3.79489899e-01,  5.96038364e-02,\n",
       "        -4.72787395e-02, -2.38899916e-01,  1.22735277e-01,\n",
       "         6.64257169e-01,  4.95660126e-01,  1.96896791e-02,\n",
       "         1.62627295e-01, -6.90609515e-01, -1.83929831e-01,\n",
       "        -2.72066861e-01,  3.42366219e-01,  3.81594062e-01,\n",
       "        -1.00714713e-01,  4.04931009e-01, -1.15194589e-01,\n",
       "         1.16429463e-01, -5.05921878e-02, -1.02755457e-01,\n",
       "         3.18194896e-01,  1.71614617e-01,  5.32682016e-02,\n",
       "         2.25811124e-01, -1.15022436e-03, -8.45160112e-02,\n",
       "         2.07186460e-01,  4.73574579e-01, -2.13644251e-01,\n",
       "         2.00719818e-01, -1.71617508e-01, -4.52112108e-01,\n",
       "        -1.41670212e-01,  7.63812214e-02,  3.82901520e-01,\n",
       "         2.98301488e-01, -4.38998044e-02,  2.45935500e-01,\n",
       "        -5.01140118e-01,  1.09841585e+00, -2.83964574e-01,\n",
       "        -4.06569839e-01,  1.09032430e-02, -8.11470598e-02,\n",
       "         4.67294544e-01,  3.52341771e-01,  6.04905412e-02,\n",
       "         3.70171279e-01, -5.86369634e-02, -6.24759942e-02,\n",
       "         2.76366532e-01,  4.42212373e-01, -1.01263262e-03,\n",
       "         1.76228762e-01,  3.80415678e-01,  2.16731086e-01,\n",
       "         1.48688838e-01,  7.30501413e-02, -1.04071081e-01,\n",
       "         2.87490010e-01,  8.55633467e-02, -1.84471160e-01,\n",
       "         2.07173079e-01,  2.60109939e-02,  1.35073036e-01,\n",
       "         2.31207833e-01,  2.70938575e-01, -8.04625005e-02,\n",
       "        -3.05502743e-01,  7.33423755e-02,  1.52213514e-01,\n",
       "        -4.23454434e-01, -1.40585333e-01, -2.49552280e-02,\n",
       "        -2.16903519e-02,  4.15626019e-01,  1.02379769e-01,\n",
       "         3.41901511e-01,  2.64982671e-01,  1.18764490e-03,\n",
       "        -2.79271185e-01,  3.24438252e-02, -1.89586356e-02,\n",
       "         4.60514069e-01,  4.66858417e-01, -6.12380564e-01,\n",
       "         6.88489199e-01, -7.29038537e-01,  1.41387917e-02,\n",
       "        -5.77374458e-01, -4.62046444e-01,  1.92022890e-01,\n",
       "         1.55189753e-01,  2.93730706e-01,  6.51477724e-02,\n",
       "         2.39355609e-01,  3.17666590e-01, -2.80681819e-01,\n",
       "         3.16031426e-02,  1.13432086e+00, -8.21175426e-02,\n",
       "        -5.09983659e-01,  1.86294422e-01, -4.08523440e-01,\n",
       "        -4.32328701e-01, -7.10868835e-02,  6.09497547e-01,\n",
       "        -7.54734933e-01, -5.82492501e-02,  2.95392096e-01,\n",
       "        -8.31155106e-03, -2.28205279e-01,  2.99749136e-01,\n",
       "         4.95472312e-01, -2.03795359e-01,  7.62350261e-02,\n",
       "        -2.52657771e-01,  6.78687036e-01, -3.10448855e-01,\n",
       "         2.87522078e-01,  3.58126611e-02, -1.21330225e+00,\n",
       "         8.07609260e-01, -9.32418779e-02,  9.83171105e-01,\n",
       "        -6.55268133e-02,  2.63597608e-01, -5.27933180e-01,\n",
       "        -2.09663004e-01,  1.41996443e-01, -1.05387658e-01,\n",
       "        -6.57341897e-01,  2.24089563e-01,  7.67509788e-02,\n",
       "         1.29386723e-01, -1.44115880e-01, -4.67528135e-01,\n",
       "        -4.71259207e-02,  8.55048358e-01,  3.54096621e-01,\n",
       "        -7.93617725e-01, -7.56144524e-02,  4.53508019e-01,\n",
       "         3.00702989e-01, -1.85289159e-02, -2.10982040e-01,\n",
       "        -7.73760974e-02,  4.45873708e-01,  2.81308234e-01,\n",
       "        -3.08734030e-01,  3.73217165e-02,  2.46337831e-01,\n",
       "         9.18557197e-02, -2.91905701e-01, -6.64588571e-01,\n",
       "        -2.34461963e-01,  2.56519318e-01,  7.46337697e-02,\n",
       "        -1.41779527e-01,  2.31278837e-02,  3.72327179e-01,\n",
       "        -1.59153447e-01, -1.30347937e-01,  3.04700673e-01,\n",
       "         6.40249133e-01,  1.43416628e-01, -3.39275271e-01,\n",
       "        -1.31532699e-01,  3.20580423e-01, -7.12698102e-01,\n",
       "        -4.02757585e-01, -7.94807374e-02,  4.48841125e-01,\n",
       "        -4.07560617e-01,  1.80891007e-01,  8.83646607e-02,\n",
       "         1.28008127e-01, -4.15463924e-01, -2.83650458e-02,\n",
       "        -6.29004359e-01,  9.61617827e-02,  4.33005132e-02,\n",
       "        -3.44583511e-01, -2.88376268e-02, -2.35068053e-02,\n",
       "         9.39056426e-02,  8.24943066e-01, -6.79400682e-01,\n",
       "        -1.91029713e-01, -1.42903835e-01, -5.85389435e-02,\n",
       "        -5.32738984e-01, -1.45220384e-01,  5.47031686e-03,\n",
       "         4.41921204e-02, -5.79699457e-01,  1.15900986e-01,\n",
       "        -4.80199516e-01,  3.90963674e-01, -3.34533751e-01,\n",
       "         1.29680723e-01, -6.29454926e-02,  1.57375067e-01,\n",
       "         2.49238238e-01, -3.36457402e-01,  6.59359932e-01,\n",
       "        -1.72671586e-01,  2.89696842e-01, -7.03773797e-01,\n",
       "        -3.96777205e-02,  5.69291174e-01,  8.47635418e-03,\n",
       "        -2.78790772e-01,  4.23781157e-01, -4.64122981e-01,\n",
       "        -1.46272957e-01, -8.39579850e-02,  4.07848865e-01,\n",
       "         4.48913008e-01, -9.66071803e-03,  3.90929282e-02,\n",
       "        -3.17137599e-01,  5.42878062e-02,  1.01132020e-01,\n",
       "        -1.50895917e+00,  5.72512627e-01,  7.98863173e-03,\n",
       "         2.29493856e-01, -2.13382244e-01, -5.77678084e-02,\n",
       "         3.43098164e-01, -6.98582351e-01,  1.80033699e-01,\n",
       "         8.28032717e-02, -2.50619739e-01,  2.88237959e-01,\n",
       "        -1.16485089e-01,  1.42832160e-01,  8.71872008e-02,\n",
       "        -1.55830562e-01,  2.54544050e-01,  2.13747144e-01,\n",
       "        -1.02460504e-01, -3.43490481e-01,  3.89057517e-01,\n",
       "         1.01411223e-01,  5.19177079e-01, -5.50797656e-02,\n",
       "         3.84730369e-01, -6.28014877e-02,  5.88106334e-01,\n",
       "         4.89041984e-01, -5.80958053e-02,  3.08243811e-01,\n",
       "        -1.36758476e-01, -5.27356751e-02, -4.90422308e-01,\n",
       "         4.34684344e-02,  7.48774052e-01, -2.79976457e-01,\n",
       "        -4.99565065e-01, -6.80709034e-02,  4.19154137e-01,\n",
       "        -1.62895977e-01,  4.85396758e-02,  4.12819028e-01,\n",
       "         2.98388422e-01,  1.29530579e-01,  3.60581815e-01,\n",
       "        -4.40344453e-01,  1.66307166e-01, -1.87493354e-01,\n",
       "         2.95032598e-02, -5.07586002e-02,  5.27493715e-01,\n",
       "         8.13883603e-01,  5.84950268e-01, -2.93078631e-01,\n",
       "         4.75632548e-01,  2.86350191e-01, -2.10794777e-01,\n",
       "         4.12281334e-01, -7.43304133e-01, -3.43387485e-01,\n",
       "         5.01847863e-01, -1.50812626e-01,  8.84588301e-01,\n",
       "         2.61749208e-01, -2.21263561e-02, -6.98703706e-01,\n",
       "         6.08341917e-02, -5.25098443e-01, -2.66055137e-01,\n",
       "        -1.75208598e-02, -1.50445983e-01,  1.25887290e-01,\n",
       "        -2.52074629e-01,  2.86807358e-01,  6.41098559e-01,\n",
       "         2.57200062e-01, -4.19283450e-01, -5.91796160e-01,\n",
       "        -2.43964404e-01,  7.26004615e-02,  4.01874632e-01,\n",
       "        -5.69986105e-01,  2.97224998e-01,  1.23744845e-01,\n",
       "         6.42767489e-01, -4.14351761e-01,  6.03710055e-01,\n",
       "        -2.41971761e-01,  1.53868094e-01, -2.71147460e-01,\n",
       "        -2.79235601e-01, -3.36940736e-01, -3.68122905e-01,\n",
       "        -1.32633716e-01,  4.70473677e-01,  2.65557766e-01,\n",
       "        -1.77168623e-01, -2.65518874e-02, -7.79491663e-02,\n",
       "        -2.23969042e-01,  2.79901773e-01,  1.76585913e-01,\n",
       "        -1.04167327e-01,  5.56723535e-01, -1.65984809e-01,\n",
       "        -1.67865887e-01, -4.13238443e-02, -9.18966904e-02,\n",
       "        -2.76650757e-01,  1.78370357e-01,  3.70581970e-02,\n",
       "        -5.13280511e-01, -3.61178458e-01,  6.89476192e-01,\n",
       "         3.12042892e-01,  3.92510295e-01,  6.17242754e-01,\n",
       "         7.37325191e-01,  3.43380243e-01, -4.22219127e-01,\n",
       "         2.96232589e-02,  6.42308593e-01, -6.33645058e-01,\n",
       "        -3.66743237e-01, -7.18803704e-01, -1.18625790e-01,\n",
       "         4.35080826e-01,  1.30911097e-02, -4.93349105e-01,\n",
       "         2.71100372e-01,  4.16862249e-01,  2.79272467e-01,\n",
       "        -3.78410429e-01, -4.61819917e-02, -2.27848142e-01,\n",
       "        -6.46564364e-01,  5.13576269e-01, -8.54680687e-02,\n",
       "         1.27736375e-01, -3.53172496e-02,  4.78174537e-01,\n",
       "         2.33810157e-01, -2.02007025e-01,  2.87226260e-01,\n",
       "        -8.71378899e-01, -2.60188013e-01,  3.78732532e-01,\n",
       "        -4.55167353e-01,  3.45677614e-01,  1.07116155e-01,\n",
       "        -2.29350686e-01,  1.54462725e-01,  5.91513216e-01,\n",
       "        -5.89219928e-02, -1.31501749e-01,  1.27688214e-01,\n",
       "         1.05098784e-02, -2.34729230e-01, -5.55870354e-01,\n",
       "        -9.40596759e-02,  2.35010222e-01, -3.02168995e-01,\n",
       "         1.54837549e-01, -5.42589486e-01, -3.43497843e-01,\n",
       "        -6.12470992e-02,  4.89127219e-01,  2.44605556e-01,\n",
       "        -2.63095647e-01, -4.57769871e-01,  8.26256275e-02,\n",
       "        -3.31248760e-01, -3.49116415e-01, -2.97723353e-01,\n",
       "        -4.11022902e-01,  1.20217010e-01,  2.28789270e-01,\n",
       "         3.39975655e-01,  2.03380473e-02,  1.16601646e-01,\n",
       "         3.41142476e-01,  3.93507808e-01, -3.61164302e-01,\n",
       "         2.77208686e-02,  2.19955623e-01, -5.93145937e-03,\n",
       "         1.25622258e-01, -6.65584505e-01,  5.21827817e-01,\n",
       "         2.35235363e-01, -7.20935315e-02,  9.47858095e-02,\n",
       "        -1.80963904e-01,  5.21819443e-02, -4.94796157e-01,\n",
       "        -1.38494253e-01,  3.28359902e-01,  6.45403489e-02,\n",
       "         6.89295828e-02,  1.19108275e-01, -6.18582726e-01,\n",
       "        -1.21185258e-01,  5.74076056e-01,  3.70301664e-01,\n",
       "        -1.23740956e-01, -2.91468129e-02,  9.29744244e-02,\n",
       "        -6.70174509e-02, -4.75383103e-01,  4.37082261e-01,\n",
       "         5.96347898e-02,  1.76237777e-01, -1.01388425e-01,\n",
       "         7.13481963e-01,  1.16766751e-01, -5.60253799e-01,\n",
       "        -1.76914275e-01, -1.49869084e-01, -5.76251864e-01,\n",
       "        -1.97945684e-02, -1.21397495e-01,  7.13960379e-02,\n",
       "        -3.23233306e-01,  2.31367618e-01, -4.49801385e-01,\n",
       "         2.68350750e-01,  1.46489665e-01, -4.19102490e-01,\n",
       "        -2.01026946e-02,  2.70746082e-01, -3.48683625e-01,\n",
       "         7.28722289e-02,  8.15881193e-02,  2.46060312e-01,\n",
       "         2.48173475e-02, -1.44963905e-01, -6.42710447e-01,\n",
       "        -1.28682256e-01,  1.59912050e-01, -2.64136717e-02,\n",
       "         2.28900254e-01, -1.43378258e-01, -1.76559210e-01,\n",
       "        -3.57482851e-01,  3.38790298e-01,  1.87259287e-01,\n",
       "         1.07954073e+00,  5.40010870e-01,  1.00767052e+00,\n",
       "         2.94888914e-01,  9.18258727e-01,  4.51445580e-01,\n",
       "        -2.24592328e-01, -1.92885712e-01,  3.04395974e-01,\n",
       "         2.04392463e-01,  2.57487178e-01,  3.36937755e-02,\n",
       "         2.88876534e-01,  6.13388121e-01, -1.21881247e-01,\n",
       "         5.56656003e-01,  3.32737938e-02,  6.63727343e-01,\n",
       "        -2.77255118e-01, -1.98443845e-01,  6.84128463e-01,\n",
       "        -3.21597666e-01, -1.54619291e-01,  9.65206623e-02,\n",
       "        -3.86971444e-01, -6.09193034e-02,  4.89961088e-01,\n",
       "        -4.43856776e-01,  1.35516620e+00, -2.70766646e-01,\n",
       "         5.76102316e-01,  1.89194247e-01, -3.97077799e-02,\n",
       "         4.09552038e-01, -3.67174923e-01, -2.95190305e-01,\n",
       "         4.78244334e-01,  4.91972119e-02,  3.83059867e-02,\n",
       "        -9.66076851e-02, -7.91613102e-01, -2.37100199e-01,\n",
       "        -4.79715765e-01,  1.00344324e+00,  2.04493105e-02,\n",
       "         3.13600451e-02, -1.59560427e-01, -5.54986894e-01,\n",
       "        -4.37821627e-01, -6.83061182e-02,  2.68455893e-01,\n",
       "         4.64554355e-02,  2.58604169e-01,  4.95873123e-01,\n",
       "         2.82530487e-02, -4.85734820e-01,  3.69572490e-01,\n",
       "        -3.33882213e-01,  3.85537952e-01,  2.84802735e-01,\n",
       "        -1.06842481e-02,  2.20586434e-02,  2.75105536e-01,\n",
       "        -3.96601170e-01, -1.59882933e-01, -1.95597634e-01,\n",
       "        -2.52525300e-01,  3.48289311e-03,  4.50058609e-01,\n",
       "         1.17548719e-01, -4.77995723e-01,  2.23091617e-01,\n",
       "         3.39268714e-01,  5.07517993e-01,  1.63427711e-01,\n",
       "        -6.55151606e-01,  5.28686225e-01,  2.97491401e-02,\n",
       "        -6.66921884e-02,  4.83669117e-02,  4.32337373e-02,\n",
       "         7.47045428e-02, -2.14133799e-01,  7.91270912e-01,\n",
       "        -2.28750736e-01,  8.88496339e-02, -8.86110663e-01,\n",
       "        -3.81577104e-01,  4.96869460e-02, -1.39067024e-02,\n",
       "         3.30713123e-01, -7.63605237e-01,  1.35116324e-01,\n",
       "         1.46096736e-01, -7.29007125e-02,  5.97595811e-01,\n",
       "         1.24619715e-03,  1.89202070e-01,  7.04685748e-01,\n",
       "         1.04116373e-01, -8.41544718e-02,  1.48115337e-01,\n",
       "         7.37088546e-02,  3.05834323e-01, -1.58286974e-01,\n",
       "         6.45517558e-02,  4.29209173e-01, -3.32256034e-02,\n",
       "        -4.03429717e-02, -2.01062739e-01,  5.72242320e-01,\n",
       "        -9.51061696e-02, -6.58860356e-02, -4.48764503e-01,\n",
       "        -2.94317424e-01,  2.81680942e-01,  2.44305462e-01,\n",
       "         6.35349035e-01,  4.75533783e-01,  6.71031773e-01,\n",
       "         2.83559382e-01,  2.05570340e-01, -7.74362087e-01,\n",
       "        -1.72955856e-01,  3.23862940e-01, -5.73528349e-01,\n",
       "        -8.48336667e-02,  2.94735700e-01, -4.09217596e-01,\n",
       "         3.42969567e-01,  5.70021987e-01, -2.67718673e-01,\n",
       "         6.21716604e-02,  4.92625833e-01,  4.73427057e-01,\n",
       "         5.85566610e-02,  6.55072406e-02,  1.01273918e+00,\n",
       "         4.14856434e-01,  6.46280274e-02,  8.89411122e-02,\n",
       "        -3.77511859e-01,  3.52075756e-01, -5.17000377e-01,\n",
       "         3.41661960e-01,  2.13463485e-01,  5.48381567e-01,\n",
       "        -4.89776671e-01,  2.27535293e-01, -4.72558618e-01,\n",
       "        -1.05034806e-01, -1.85540989e-01,  8.55857134e-02,\n",
       "         3.92160535e-01, -1.26717955e-01,  1.30217880e-01,\n",
       "         3.61258298e-01,  2.89988339e-01, -3.50309968e-01,\n",
       "        -7.40373582e-02, -5.90727627e-01, -1.70494899e-01,\n",
       "        -8.52401853e-02, -4.47466597e-02, -6.92238659e-02,\n",
       "         1.52129173e-01, -8.71732831e-03, -6.94190264e-02,\n",
       "        -3.36235672e-01,  6.91849828e-01, -3.34672987e-01,\n",
       "        -3.42994571e-01,  1.15428925e-01,  3.36558074e-01,\n",
       "         2.19261795e-01,  2.15601355e-01, -9.50252175e-01,\n",
       "        -7.31060803e-01,  6.71824276e-01, -1.18556872e-01,\n",
       "        -1.92157030e-02, -3.20058346e-01,  2.96723187e-01,\n",
       "        -3.32244597e-02,  6.24170601e-01,  2.61497974e-01,\n",
       "         8.48430693e-02, -3.37280095e-01,  2.46125728e-01,\n",
       "         3.99142087e-01,  3.00562441e-01,  5.03689408e-01,\n",
       "         6.39101639e-02,  2.83556767e-02, -7.11413920e-01,\n",
       "         8.99476856e-02,  2.13975459e-01, -9.97653455e-02,\n",
       "         7.75516808e-01,  1.16380453e-02, -3.78408253e-01,\n",
       "        -2.43780643e-01, -3.98790747e-01,  2.53355205e-01,\n",
       "         7.38154501e-02,  2.58685708e-01,  4.01825368e-01,\n",
       "        -5.30286357e-02,  1.14871427e-01, -2.15705335e-01,\n",
       "         1.79929197e-01, -2.77779698e-01,  2.70297453e-02,\n",
       "         1.48383146e-02, -4.09586787e-01, -3.52707744e-01,\n",
       "         5.09223193e-02, -3.35083485e-01,  5.39713129e-02,\n",
       "         1.69051483e-01,  2.26953357e-01, -3.54317337e-01,\n",
       "         2.75365740e-01, -3.11418653e-01,  3.72863531e-01,\n",
       "         2.04496562e-01,  6.57822013e-01, -1.44745857e-01,\n",
       "         2.93587208e-01, -1.44025832e-01,  4.77760136e-01,\n",
       "        -3.40859056e-01, -6.84090853e-02,  3.58100861e-01,\n",
       "         1.34411424e-01,  2.65466809e-01, -7.77751327e-01,\n",
       "         1.61987916e-02, -9.29716229e-01,  1.31310612e-01,\n",
       "         4.32891726e-01,  3.29352021e-01,  4.44108218e-01,\n",
       "        -2.94482797e-01,  4.83887941e-02,  2.23728746e-01,\n",
       "         9.32679057e-01,  2.92206764e-01, -3.04755241e-01,\n",
       "         5.26715338e-01, -6.32964075e-01, -2.96196640e-01,\n",
       "         6.63211346e-01,  4.06951964e-01, -1.96554616e-01,\n",
       "        -3.19574416e-01, -3.16347867e-01,  2.85248876e-01,\n",
       "        -2.57176876e-01,  9.75591540e-02,  3.47755104e-01,\n",
       "        -3.06556910e-01, -9.75151211e-02, -4.69197690e-01]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = \"k ngon\"\n",
    "\n",
    "tokenized = [tokenize_line(document)]\n",
    "\n",
    "mask = [np.where(np.array(tokenized) == 1, 0, 1)]\n",
    "\n",
    "extract_line(tokenized, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "step = 1\n",
    "mask = test_attention_mask[i:i+step]\n",
    "tokenized = tokenized_test_x[i:i+step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mask\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed tập train\n",
    "train_size = len(tokenized_train_x)\n",
    "EMBED_SIZE = 768\n",
    "train_features = np.zeros(shape=(train_size, EMBED_SIZE))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "step = 20\n",
    "for i in tqdm(range(0, train_size, step)):\n",
    "  mask = train_attention_mask[i:i+step]\n",
    "  tokenized = tokenized_train_x[i:i+step]\n",
    "  feature = extract_line(tokenized, mask)\n",
    "  train_features[i:i+step] = feature\n",
    "\n",
    "print('Finish extracting features after %d seconds' %(time.time() - start))\n",
    "print('Output shape: ', train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53593185768843468d040c7d2f228eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish extracting features after 909 seconds\n",
      "Output shape:  (2291, 768)\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện tương tự trên tập test\n",
    "test_size = len(tokenized_test_x)\n",
    "EMBED_SIZE = 768\n",
    "test_features = np.zeros(shape=(test_size, EMBED_SIZE))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "step = 20\n",
    "for i in tqdm(range(0, test_size, step)):\n",
    "  mask = test_attention_mask[i:i+step]\n",
    "  tokenized = tokenized_test_x[i:i+step]\n",
    "  feature = extract_line(tokenized, mask)\n",
    "  test_features[i:i+step] = feature\n",
    "\n",
    "print('Finish extracting features after %d seconds' %(time.time() - start))\n",
    "print('Output shape: ', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# xác định đường dẫn tới thư mục hiện tại\n",
    "current_dir = os.path.dirname(os.path.abspath(\"4. phoBERT.ipynb\"))\n",
    "\n",
    "# đường dẫn tới file cần lưu\n",
    "bert_features_path = os.path.join(current_dir, 'bert_features.sav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lưu danh sách embed\n",
    "pickle.dump(train_features, open(bert_features_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test_features_path = os.path.join(current_dir, 'bert_test_features.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_features, open(bert_test_features_path, 'wb'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá khả năng phân cụm của PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded shape:  (9160, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# visualize embedded vector dưới góc nhìn 2 chiều\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "x_2d = tsne.fit_transform(train_features)\n",
    "print('Embedded shape: ', x_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize\n",
    "# plt.figure(figsize=(20, 12))\n",
    "# color_map = {\n",
    "#     0: 'red', 1: 'blue', 2: 'lightgreen'\n",
    "# }\n",
    "# # labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# train_y = np.array(train_y)\n",
    "\n",
    "# for idx, label in enumerate(labels):\n",
    "#   plt.scatter(x=x_2d[train_y == label, 0], y=x_2d[train_y == label, 1], c=color_map[idx], marker='o', label=label)\n",
    "\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# plt.legend()\n",
    "# plt.title('2D Visualization of Training Data')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vector embedding đã lưu\n",
    "train_features = pickle.load(open(bert_features_path, 'rb'))\n",
    "test_features = pickle.load(open(bert_test_features_path, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression finish training after 9 second\n"
     ]
    }
   ],
   "source": [
    "logisticReg = LogisticRegression(max_iter=100_000)\n",
    "\n",
    "start = time.time()\n",
    "logisticReg.fit(train_features, train_y)\n",
    "\n",
    "print('Logistic Regression finish training after %d second' %(time.time() - start))\n",
    "\n",
    "bert_logreg_path = './bert_logreg.sav'\n",
    "pickle.dump(logisticReg, open(bert_logreg_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7642950676560454\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá độ chính xác của mô hình Logistic Regression\n",
    "y_pred = logisticReg.predict(test_features)\n",
    "\n",
    "acc = np.mean(y_pred == np.array(test_y))\n",
    "\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.73      0.72       675\n",
      "           0       0.29      0.14      0.19       239\n",
      "           1       0.82      0.89      0.85      1377\n",
      "\n",
      "    accuracy                           0.76      2291\n",
      "   macro avg       0.61      0.59      0.59      2291\n",
      "weighted avg       0.74      0.76      0.75      2291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(test_y, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize bằng heat map\n",
    "plt.figure(figsize=(16, 16))\n",
    "conf_matrix = confusion_matrix(test_y, y_pred, labels=labels)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='YlOrRd' , xticklabels=labels, yticklabels=labels)\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier finish training after 23 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm = SVC()\n",
    "\n",
    "start = time.time()\n",
    "svm.fit(train_features, train_y)\n",
    "print('SVM classifier finish training after %d seconds' %(time.time() - start))\n",
    "\n",
    "bert_svm_path = './bert_svm.sav'\n",
    "pickle.dump(svm, open(bert_svm_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7861195984286338\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Đánh giá độ chính xác\n",
    "y_pred = svm.predict(test_features)\n",
    "\n",
    "acc = np.mean(y_pred == np.array(test_y))\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.76      0.75       675\n",
      "           0       0.50      0.00      0.01       239\n",
      "           1       0.81      0.93      0.87      1377\n",
      "\n",
      "    accuracy                           0.79      2291\n",
      "   macro avg       0.68      0.57      0.54      2291\n",
      "weighted avg       0.75      0.79      0.74      2291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize bằng heat map\n",
    "plt.figure(figsize=(16, 16))\n",
    "conf_matrix = confusion_matrix(test_y, y_pred, labels=labels)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='YlOrRd' , xticklabels=labels, yticklabels=labels)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_svm.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svm, \"clf_svm.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS338",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
